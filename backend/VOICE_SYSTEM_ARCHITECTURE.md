# Architecture SystÃ¨me Voix - HelÅ

## ğŸ¯ Objectif

Permettre aux utilisateurs de **converser vocalement** avec l'IA thÃ©rapeutique, comme lors d'un appel avec un thÃ©rapeute.

---

## ğŸ—ï¸ Architecture ProposÃ©e

### Composants

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        FRONTEND                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚  â”‚   Settings   â”‚         â”‚  VoiceChat   â”‚                â”‚
â”‚  â”‚              â”‚         â”‚              â”‚                â”‚
â”‚  â”‚ - Mode       â”‚         â”‚ - Micro      â”‚                â”‚
â”‚  â”‚ - Voix       â”‚         â”‚ - Speaker    â”‚                â”‚
â”‚  â”‚ - Vitesse    â”‚         â”‚ - WebRTC     â”‚                â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚                                  â”‚                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                                   â”‚ WebSocket
                                   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        BACKEND                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                  â–¼                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚           API GATEWAY (port 8000)               â”‚       â”‚
â”‚  â”‚                                                 â”‚       â”‚
â”‚  â”‚  /ws/voice  â† WebSocket endpoint                â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                     â”‚                â”‚                      â”‚
â”‚                     â–¼                â–¼                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚   VOICE SERVICE      â”‚  â”‚   AI ENGINE          â”‚       â”‚
â”‚  â”‚   (port 8003)        â”‚  â”‚   (port 8001)        â”‚       â”‚
â”‚  â”‚                      â”‚  â”‚                      â”‚       â”‚
â”‚  â”‚  - STT (Whisper)     â”‚  â”‚  - TherapeuticEngine â”‚       â”‚
â”‚  â”‚  - TTS (Piper/Edge)  â”‚  â”‚  - LLM Router        â”‚       â”‚
â”‚  â”‚  - Audio Processing  â”‚  â”‚  - Methods Engine    â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”§ Technologies RecommandÃ©es

### 1. Speech-to-Text (STT)

**Option 1 : Whisper (OpenAI) - RECOMMANDÃ‰**
- âœ… Open source
- âœ… TrÃ¨s haute qualitÃ©
- âœ… Support franÃ§ais excellent
- âœ… Peut tourner localement (GPU) ou via API
- âš ï¸ NÃ©cessite GPU pour temps rÃ©el local

**Installation :**
```bash
pip install openai-whisper
# ou
pip install faster-whisper  # Version optimisÃ©e
```

**Option 2 : Vosk**
- âœ… 100% offline
- âœ… LÃ©ger
- âš ï¸ QualitÃ© infÃ©rieure Ã  Whisper

### 2. Text-to-Speech (TTS)

**Option 1 : Piper TTS - RECOMMANDÃ‰ pour privacy**
- âœ… 100% open source
- âœ… Fonctionne offline
- âœ… Voix naturelles
- âœ… Rapide (temps rÃ©el)
- âœ… Respect vie privÃ©e

**Installation :**
```bash
pip install piper-tts
```

**Voix franÃ§aises disponibles :**
- `fr_FR-siwis-medium` (neutre)
- `fr_FR-upmc-medium` (fÃ©minine)
- `fr_FR-tom-medium` (masculine)

**Option 2 : Edge TTS - RECOMMANDÃ‰ pour qualitÃ©**
- âœ… Gratuit (utilise API Microsoft Edge)
- âœ… Voix trÃ¨s naturelles
- âœ… Facile Ã  utiliser
- âš ï¸ NÃ©cessite connexion internet
- âš ï¸ DonnÃ©es envoyÃ©es Ã  Microsoft

**Installation :**
```bash
pip install edge-tts
```

**Voix franÃ§aises disponibles :**
- `fr-FR-DeniseNeural` (fÃ©minine, douce)
- `fr-FR-HenriNeural` (masculine, calme)
- `fr-FR-EloiseNeural` (fÃ©minine, chaleureuse)
- `fr-FR-RemyMultilingualNeural` (masculine, neutre)

### 3. Streaming Audio

**WebRTC** (Web Real-Time Communication)
- âœ… Standard web pour audio/vidÃ©o temps rÃ©el
- âœ… Faible latence
- âœ… Support navigateurs

**WebSocket** (pour contrÃ´le)
- âœ… Bidirectionnel
- âœ… Temps rÃ©el
- âœ… Facile Ã  implÃ©menter

---

## ğŸ“ Structure de Fichiers ProposÃ©e

```
backend/
â”œâ”€â”€ voice-service/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ main.py                    # FastAPI app
â”‚   â”‚   â”œâ”€â”€ stt_engine.py              # Speech-to-Text
â”‚   â”‚   â”œâ”€â”€ tts_engine.py              # Text-to-Speech
â”‚   â”‚   â”œâ”€â”€ audio_processor.py         # Traitement audio
â”‚   â”‚   â””â”€â”€ voice_session_manager.py   # Gestion sessions
â”‚   â”œâ”€â”€ models/                        # ModÃ¨les Whisper/Piper
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ Dockerfile
â”‚
â”œâ”€â”€ api-gateway/
â”‚   â””â”€â”€ app/
â”‚       â””â”€â”€ voice_websocket.py         # WebSocket handler (NOUVEAU)
â”‚
frontend/
â””â”€â”€ src/
    â”œâ”€â”€ ui/
    â”‚   â”œâ”€â”€ VoiceChat.jsx              # Interface voix (NOUVEAU)
    â”‚   â””â”€â”€ Settings.jsx               # âœ… CRÃ‰Ã‰
    â”‚
    â””â”€â”€ styles/
        â”œâ”€â”€ voice-chat.css             # Styles voix (NOUVEAU)
        â””â”€â”€ settings.css               # âœ… CRÃ‰Ã‰
```

---

## ğŸ”„ Flux de Conversation Vocale

### 1. Initialisation

```
User clicks "DÃ©marrer conversation vocale"
    â”‚
    â–¼
Frontend: VoiceChat.jsx
    â”‚
    â”œâ”€ Request microphone permission
    â”œâ”€ Load user voice preferences (voiceId, speed, pitch)
    â””â”€ Connect WebSocket to /ws/voice
    â”‚
    â–¼
Backend: API Gateway
    â”‚
    â””â”€ Create voice session
        â””â”€ Initialize STT + TTS engines
```

### 2. Conversation Loop

```
User speaks
    â”‚
    â–¼
Frontend: Capture audio (MediaRecorder)
    â”‚
    â””â”€ Send audio chunks via WebSocket
    â”‚
    â–¼
Backend: Voice Service
    â”‚
    â”œâ”€ STT: Audio â†’ Text
    â”‚   â””â”€ Whisper.transcribe(audio)
    â”‚
    â”œâ”€ AI Engine: Text â†’ Response
    â”‚   â””â”€ TherapeuticEngine.run_pipeline()
    â”‚
    â”œâ”€ TTS: Response â†’ Audio
    â”‚   â””â”€ Piper/Edge.synthesize(text, voiceId, speed, pitch)
    â”‚
    â””â”€ Send audio chunks back via WebSocket
    â”‚
    â–¼
Frontend: Play audio (AudioContext)
    â”‚
    â””â”€ Display transcript + avatar animation
```

### 3. Gestion d'Erreurs

```
Network error
    â”‚
    â””â”€ Fallback to text chat
    
Microphone unavailable
    â”‚
    â””â”€ Show error + suggest text chat
    
TTS service down
    â”‚
    â””â”€ Display text only
```

---

## ğŸ¨ Interface Utilisateur (VoiceChat.jsx)

### Composants Visuels

```jsx
<VoiceChat>
  <AvatarRoom 
    mode="voice" 
    isSpeaking={isAISpeaking}
    audioLevel={audioLevel}
  />
  
  <VoiceControls>
    <MicButton 
      isRecording={isRecording}
      onClick={toggleRecording}
    />
    <VolumeSlider />
    <EndCallButton />
  </VoiceControls>
  
  <TranscriptDisplay>
    {messages.map(msg => (
      <TranscriptMessage role={msg.role}>
        {msg.text}
      </TranscriptMessage>
    ))}
  </TranscriptDisplay>
</VoiceChat>
```

### Ã‰tats

- `isRecording` : Micro actif
- `isAISpeaking` : IA en train de parler
- `audioLevel` : Niveau audio (pour visualisation)
- `messages` : Historique transcriptions
- `connectionStatus` : 'connecting' | 'connected' | 'disconnected'

---

## ğŸ” SÃ©curitÃ© et Vie PrivÃ©e

### DonnÃ©es Audio

**Option 1 : Piper TTS (100% local)**
- âœ… Aucune donnÃ©e envoyÃ©e Ã  l'extÃ©rieur
- âœ… Conforme RGPD
- âœ… Pas de dÃ©pendance externe

**Option 2 : Edge TTS (cloud)**
- âš ï¸ Audio envoyÃ© Ã  Microsoft
- âš ï¸ NÃ©cessite consentement explicite
- âœ… QualitÃ© supÃ©rieure

### Recommandation

**Offrir les deux options :**
- Par dÃ©faut : **Piper TTS** (privacy-first)
- Option avancÃ©e : **Edge TTS** (qualitÃ© supÃ©rieure)
- Afficher clairement dans Settings quelle option envoie des donnÃ©es

---

## ğŸ“Š Estimation Ressources

### CPU/GPU

| Composant | CPU | GPU | RAM |
|-----------|-----|-----|-----|
| Whisper (tiny) | 1 core | - | 1 GB |
| Whisper (base) | 2 cores | - | 2 GB |
| Whisper (small) | 4 cores | CUDA | 4 GB |
| Piper TTS | 1 core | - | 500 MB |
| Edge TTS | Minimal | - | Minimal |

### Latence

| Ã‰tape | Latence |
|-------|---------|
| STT (Whisper tiny) | 200-500ms |
| AI Response | 1-3s |
| TTS (Piper) | 100-300ms |
| **Total** | **1.5-4s** |

---

## ğŸš€ Plan d'ImplÃ©mentation

### Phase 1 : Backend Voice Service (2-3 jours)

1. CrÃ©er `backend/voice-service/`
2. ImplÃ©menter STT avec Whisper
3. ImplÃ©menter TTS avec Piper + Edge
4. CrÃ©er WebSocket handler
5. Tests unitaires

### Phase 2 : Frontend VoiceChat (2-3 jours)

1. CrÃ©er `VoiceChat.jsx`
2. IntÃ©grer WebRTC/WebSocket
3. CrÃ©er contrÃ´les audio
4. Animer avatar selon audio
5. Tests utilisateur

### Phase 3 : IntÃ©gration (1-2 jours)

1. Connecter Settings â†’ VoiceChat
2. Persister prÃ©fÃ©rences voix
3. Tests end-to-end
4. Optimisation latence

---

## ğŸ“ Exemple Code

### Backend : TTS Engine (Piper)

```python
from piper import PiperVoice

class TTSEngine:
    def __init__(self):
        self.voices = {
            'piper-fr-siwis-medium': PiperVoice.load('fr_FR-siwis-medium')
        }
    
    def synthesize(self, text: str, voice_id: str, speed: float = 1.0):
        voice = self.voices.get(voice_id)
        audio = voice.synthesize(text, speed=speed)
        return audio  # bytes
```

### Frontend : WebSocket Connection

```javascript
const ws = new WebSocket('ws://localhost:8000/ws/voice')

ws.onmessage = (event) => {
  const data = JSON.parse(event.data)
  
  if (data.type === 'audio') {
    playAudio(data.audio)  // Base64 â†’ AudioContext
  } else if (data.type === 'transcript') {
    addMessage(data.text, data.role)
  }
}

// Send audio
mediaRecorder.ondataavailable = (event) => {
  ws.send(event.data)
}
```

---

## âœ… Checklist ComplÃ¨te

- [ ] CrÃ©er `backend/voice-service/`
- [ ] Installer Whisper + Piper/Edge
- [ ] ImplÃ©menter STT engine
- [ ] ImplÃ©menter TTS engine
- [ ] CrÃ©er WebSocket handler
- [ ] CrÃ©er `frontend/src/ui/VoiceChat.jsx`
- [ ] IntÃ©grer WebRTC
- [ ] CrÃ©er contrÃ´les audio
- [ ] Animer avatar selon audio
- [ ] Tester latence
- [ ] Documenter API
- [ ] Tests utilisateur

